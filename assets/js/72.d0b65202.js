(window.webpackJsonp=window.webpackJsonp||[]).push([[72],{417:function(a,e,v){"use strict";v.r(e);var _=v(42),t=Object(_.a)({},(function(){var a=this,e=a.$createElement,v=a._self._c||e;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("p",[a._v("初步接触大数据，各种概念和新名词太多。Hadoop+HBase+Flume+Kafka一套组合拳就能给整懵逼了，单独搜索某一个都是一大堆专业名称，实在搞不清楚每个组件的具体作用是什么。\n本文的目的就是概括总结大数据相关的各种概念与专业术语，为后续的学习打下基础。\n")]),a._v(" "),v("h1",{attrs:{id:"专业术语"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#专业术语"}},[a._v("#")]),a._v(" 专业术语")]),a._v(" "),v("hr"),a._v(" "),v("h2",{attrs:{id:"批式、流式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#批式、流式"}},[a._v("#")]),a._v(" 批式、流式")]),a._v(" "),v("blockquote",[v("p",[a._v("大数据处理系统可分为批式(batch)大数据和流式(streaming)大数据两类。其中，批式大数据又被称为历史大数据，流式大数据又被称为实时大数据。")])]),a._v(" "),v("h2",{attrs:{id:"etl"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#etl"}},[a._v("#")]),a._v(" ETL")]),a._v(" "),v("blockquote",[v("p",[a._v("ETL是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。")])]),a._v(" "),v("p",[a._v("通常ETL操作指的就是数据采集->数据治理->数据存储这一系列过程(很多架构图中ETL指离线数据采集的过程)。")]),a._v(" "),v("h2",{attrs:{id:"消息队列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息队列"}},[a._v("#")]),a._v(" 消息队列")]),a._v(" "),v("p",[a._v('"消息"是在两台计算机间传送的数据单位。消息可以非常简单，例如只包含文本字符串；也可以更复杂，可能包含嵌入对象。')]),a._v(" "),v("p",[a._v("高可用、分布式、高并发架构下消息队列的应用场景很多，我们可以借助消息队列技术实现大数据场景下的数据同步。\n当前使用较多的消息队列有RabbitMQ、ActiveMQ、RocketMQ、Kafka等等。")]),a._v(" "),v("h2",{attrs:{id:"数据仓库"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库"}},[a._v("#")]),a._v(" 数据仓库")]),a._v(" "),v("p",[a._v('数据仓库，英文名称Data Warehouse，简写为DW。数据仓库不是指数据库，是一个很大的数据存储集合，出于企业的分析性报告和决策支持目的而创建。\n数据仓库的输入方是各种各样的数据源(Mysql、MongoDB等等)，最终的输出用于企业的数据分析、数据挖掘、数据报表等方向。\n据仓库本身并不"生产"任何数据，同时自身也不需要"消费"任何的数据，数据仓库是为分析数据而设计的，数据来源于外部，并且开放给外部应用，这也是为什么叫"仓库"')]),a._v(" "),v("p",[a._v("主流数据仓库： 基于Hadoop的开源数据仓库Hive")]),a._v(" "),v("h2",{attrs:{id:"结构化、半结构化和非结构化数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#结构化、半结构化和非结构化数据"}},[a._v("#")]),a._v(" 结构化、半结构化和非结构化数据")]),a._v(" "),v("p",[a._v("关系型数据库(RDBMS)、非关系型数据库(NoSQL)、数据仓库(DW)中会涉及结构化数据，非结构化数据，半结构化数据的概念。")]),a._v(" "),v("p",[a._v("结构化数据：即行数据，存储在数据库里，可以用二维表结构来逻辑表达实现的数据")]),a._v(" "),v("p",[a._v("非结构化数据：非结构化数据,就是没有固定结构的数据，包含全部格式的办公文档、文本、图片、XML、HTML、各类报表、图像和音频/视频信息等等。一般直接整体进行存储，而且一般存储为二进制的数据格式")]),a._v(" "),v("p",[a._v("半结构化数据：半结构化数据可以通过灵活的键值调整获取相应信息，且数据的格式不固定，如json，同一键值下存储的信息可能是数值型的，可能是文本型的，也可能是字典或者列表，这些属性的顺序并不重要，常见的半结构数据有XML和JSON。")]),a._v(" "),v("p",[a._v("一般来讲，结构化数据只占10%以内的比例，但是就是这10%以内的数据浓缩了过去很久以来的企业各个方面的数据需求，发展也已经成熟。但是随着大数据需求处理的大态势，对于结构化以外数据的处理越来越有市场，所以处理非结构化、半结构化的数据库，会慢慢成为数据处理的主流。")]),a._v(" "),v("h1",{attrs:{id:"hadoop"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hadoop"}},[a._v("#")]),a._v(" Hadoop")]),a._v(" "),v("hr"),a._v(" "),v("blockquote",[v("p",[a._v("Hadoop是一个Java开源框架，它允许在整个集群使用简单编程模型计算机的分布式环境存储并处理大数据。它的目的是从单一的服务器到上千台机器的扩展，每一个台机器都可以提供本地计算和存储。\n概念还是很抽象的，简单理解：")])]),a._v(" "),v("ol",[v("li",[a._v("Hadoop是专为离线和大规模数据分析而设计的")]),a._v(" "),v("li",[a._v("Hadoop的核心是HDFS和MapReduce,HDFS为海量的数据提供了存储，MapReduce则为海量的数据提供了计算")])]),a._v(" "),v("p",[a._v("hadoop可以实现很多功能，因为没有具体使用过hadoop，从其核心来看主要功能：")]),a._v(" "),v("ol",[v("li",[a._v("大数据量分布存储")]),a._v(" "),v("li",[a._v("海量数据分析")])]),a._v(" "),v("p",[a._v("其他细节不过多查找，直接看一下核心的两个概念HDFS、MapReduce")]),a._v(" "),v("h2",{attrs:{id:"hdfs"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hdfs"}},[a._v("#")]),a._v(" HDFS")]),a._v(" "),v("blockquote",[v("p",[a._v("Hadoop的分布式文件存储系统(Hadoop Distributed File System)。")])]),a._v(" "),v("p",[a._v("HDFS产生背景:\n随着数据量越来越大，在一个操作系统管辖的范围内存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。\nHDFS只是分布式文件管理系统中的一种。")]),a._v(" "),v("p",[a._v("HDFS概念:"),v("br"),a._v("\nHDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件。\n其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。"),v("br"),a._v("\nHDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。")]),a._v(" "),v("p",[a._v("HDFS特点：")]),a._v(" "),v("ol",[v("li",[a._v("分布式存储\n当你从Hadoop集群中的十台机器中的任何一台访问Hadoop分布式文件系统时，你会感觉到你已经登录到一台具有10TB存储容量的大型机器（总计存储十台以上的机器）。这是什么意思？这意味着您可以存储一个10TB的大文件，这个文件将分布在十台机器上（每个1TB）。所以，它不限于每台机器的物理边界。")]),a._v(" "),v("li",[a._v("并行计算\n我们可以利用分布式存储进行并行计算。假设在一台机器上处理1TB文件需要43分钟。那么，现在告诉我，如果在具有类似配置的Hadoop集群中有10台机器，处理相同的1TB文件需要多长时间？4.3分钟，对！这里发生了什么？每个节点并行处理1TB文件的一部分。因此，43分钟的工作，现在只需要4.3分钟完成，因为工作分了十几台机器。")]),a._v(" "),v("li",[a._v("水平可伸缩性\n当集群的容量不够时，可以扩展某一台机器的硬件，但是必须要重启机器。水平可伸缩性的意思可以向现有集群添加更多节点(机器)，而不是增加单个机器的硬件容量。而最重要的是，不需要停止系统。")])]),a._v(" "),v("h2",{attrs:{id:"mapreduce"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce"}},[a._v("#")]),a._v(" MapReduce")]),a._v(" "),v("blockquote",[v("p",[a._v("概要：MapReduce最早是由Google提出的分布式数据处理模型，是Hadoop的主要组成之一，承担大批量数据的计算功能")])]),a._v(" "),v("p",[a._v("很多计算在概念上很直观，但由于输入数据很大，为了能在合理的时间内完成，这些计算必须分布在数以百计数以千计的机器上。\n简单把MapReduce理解成一种并行计算的解决方案吧。")]),a._v(" "),v("h3",{attrs:{id:"应用场景"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[a._v("#")]),a._v(" 应用场景")]),a._v(" "),v("p",[a._v("应用场景很多，核心点还是大数据的计算与分析能力：")]),a._v(" "),v("ol",[v("li",[a._v("搜索：网页爬取、倒排索引、PageRank。")]),a._v(" "),v("li",[a._v("Web 访问日志分析：")]),a._v(" "),v("li",[a._v("分析和挖掘用户在 Web 上的访问、购物行为特征，实现个性化推荐。")]),a._v(" "),v("li",[a._v("分析用户访问行为。")]),a._v(" "),v("li",[a._v("文本统计分析：")]),a._v(" "),v("li",[a._v("莫言小说的 WordCount、词频 TFIDF 分析。")]),a._v(" "),v("li",[a._v("学术论文、专利文献的引用分析和统计。")]),a._v(" "),v("li",[a._v("维基百科数据分析等。")]),a._v(" "),v("li",[a._v("海量数据挖掘：非结构化数据、时空数据、图像数据的挖掘。")]),a._v(" "),v("li",[a._v("机器学习：监督学习、无监督学习、分类算法如决策树、SVM 等。")]),a._v(" "),v("li",[a._v("自然语言处理：")]),a._v(" "),v("li",[a._v("基于大数据的训练和预测。")]),a._v(" "),v("li",[a._v("基于语料库构建单词同现矩阵，频繁项集数据挖掘、重复文档检测等。")]),a._v(" "),v("li",[a._v("广告推荐：用户点击（CTR）和购买行为（CVR）预测。")])]),a._v(" "),v("h3",{attrs:{id:"处理流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#处理流程"}},[a._v("#")]),a._v(" 处理流程")]),a._v(" "),v("p",[a._v("MapReduce处理数据过程主要分成Map和Reduce两个阶段，首先执行Map阶段，再执行Reduce阶段。\n这四个阶段又分为四个步骤：split, map, shuffle, reduce。")]),a._v(" "),v("p",[a._v("拆分(split):在正式执行Map前，需要将输入数据进行"),v("code",[a._v("分片")]),a._v("。所谓"),v("code",[a._v("分片")]),a._v("，就是将输入数据切分为大小相等的数据块，每一块作为单个Map Worker的输入被处理，以便于多个Map Worker同时工作")]),a._v(" "),v("p",[a._v("映射(map):分片完毕后，多个Map Worker便可同时工作。每个Map Worker在读入各自的数据后，进行计算处理，最终输出给Reduce。Map Worker在输出数据时，需要为每一条输出数据指定一个 Key，这个 Key值决定了这条数据将会被发送给哪一个Reduce Worker。Key值和 Reduce Worker是多对一的关系，具有相同Key的数据会被发送给同一个Reduce Worker，单个Reduce Worker有可能会接收到多个Key值的数据。")]),a._v(" "),v("p",[a._v("洗牌(shuffle):在进入Reduce阶段之前，MapReduce框架会对数据按照Key值排序，使得具有相同Key的数据彼此相邻。如果您指定了合并操作（Combiner），框架会调用 Combiner，将具有相同Key的数据进行聚合。")]),a._v(" "),v("p",[a._v("缩减(reduce)：接下来进入Reduce阶段。相同Key的数据会到达同一个Reduce Worker。同一个Reduce Worker会接收来自多个Map Worker的数据。每个Reduce Worker会对Key相同的多个数据进行Reduce 操作。最后，一个 Key的多条数据经过 Reduce的作用后，将变成一个值。")]),a._v(" "),v("p",[a._v("看一个阿里云WordCount的例子：\n假设存在一个文本 a.txt，文本内每行是一个数字，您要统计每个数字出现的次数。文本内的数字称为 Word，数字出现的次数称为 Count。如果 MaxCompute Mapreduce 完成这一功能，需要经历以下流程，如下图所示\n"),v("img",{attrs:{src:"/images/ref/MapReduce%E7%A4%BA%E4%BE%8B.jpg",alt:"Alt text"}})]),a._v(" "),v("h2",{attrs:{id:"hbase"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hbase"}},[a._v("#")]),a._v(" HBase")]),a._v(" "),v("p",[a._v("Hadoop借助HDFS只能执行批量处理，并且只以顺序方式访问数据。这意味着必须搜索整个数据集，即使是最简单的搜索工作。")]),a._v(" "),v("p",[a._v("当处理结果在另一个庞大的数据集，也是按顺序处理一个巨大的数据集。在这一点上，一个新的解决方案，需要访问数据中的任何点（随机访问）单元。")]),a._v(" "),v("p",[a._v("HBase是建立在Hadoop文件系统(HDFS)之上的一个高可靠性、高性能、面向列、可伸缩的分布式存储系统,就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。\n利用HBase技术可在廉价PC Server上搭建起大规模结构化存储集群。")]),a._v(" "),v("p",[a._v("HBase首先是一个"),v("code",[a._v("数据库")]),a._v(",不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库,当然也支持存储结构化数据。另一个不同的是HBase"),v("code",[a._v("基于列")]),a._v("的而不是基于行的模式。")]),a._v(" "),v("blockquote",[v("p",[a._v("总结:Hbase是建立在HDFS之上面向列的Nosql 、分布式数据库")])]),a._v(" "),v("h3",{attrs:{id:"面向列和面向行"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#面向列和面向行"}},[a._v("#")]),a._v(" 面向列和面向行")]),a._v(" "),v("p",[a._v("面向行其实说的就是我们熟悉的RDBMS，存储的数据都是一行一行的。面向行存储的数据库主要适合于事务性要求严格场合，或者说面向行存储的存储系统适合OLTP。")]),a._v(" "),v("p",[a._v("Hbase,Bigtable都属于面向列存储的分布式存储系统。面向列的概念有点复杂，主要是表结构的设计方面吧，在这里深究也没有好的效果，以后真正使用过了在理解吧。")]),a._v(" "),v("h3",{attrs:{id:"oltp和olap"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#oltp和olap"}},[a._v("#")]),a._v(" OLTP和OLAP")]),a._v(" "),v("p",[a._v("数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）。\nOLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。")]),a._v(" "),v("h1",{attrs:{id:"日志采集"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#日志采集"}},[a._v("#")]),a._v(" 日志采集")]),a._v(" "),v("hr"),a._v(" "),v("p",[a._v("在大概了解了Hadoop后我们应当知道Hadoop只具有数据存储与分析的功能，数据从何而来，对于数据的采集是十分重要的一步。\n主要了解两个日志采集系统Scribe、Flume，它们可以将日志数据采集到HDFS或者HBase。")]),a._v(" "),v("h2",{attrs:{id:"scribe"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#scribe"}},[a._v("#")]),a._v(" Scribe")]),a._v(" "),v("p",[a._v("Scribe是Facebook开源的分布式日志搜集系统，架构简单，日志格式灵活，且支持异步发送消息和队列。\n非常适合用于用户行为分析的基础数据收集，支持hadoop。配合thrift，可以跨语言和平台进行数据收集，非常优秀，性能也非常卓越。\nthrift就不细了解了，是一个RPC框架，也是Facebook的一个东东。")]),a._v(" "),v("h2",{attrs:{id:"flume"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#flume"}},[a._v("#")]),a._v(" Flume")]),a._v(" "),v("p",[a._v("Flume是由Cloudera软件公司提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，目前是Apache下的一个孵化项目。\nFlume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力 。Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统），支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。")]),a._v(" "),v("h1",{attrs:{id:"大数据分析"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大数据分析"}},[a._v("#")]),a._v(" 大数据分析")]),a._v(" "),v("hr"),a._v(" "),v("p",[a._v("大数据分析，特别是大数据实时分析的实现需要借助一些大数据分析工具，主要是一些开源软件。\n大概分为两个流派，一个叫做"),v("code",[a._v("MOLAP")]),a._v(" ，它在设计之初就是想把数据结构变成一个多维数据库，这样查询起来既快又方便。\n另一个叫"),v("code",[a._v("ROLAP")]),a._v("，企图用传统关系型数据库去构建多维数据库，因为像MySQL、Hive这种传统数据库是非常方便的。\n总的来说，开源的大概有两条路，一条就是原生的支持多维的，另一条就是通过关系型数据库去模拟这种多维查询。")]),a._v(" "),v("h2",{attrs:{id:"rolap流派"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#rolap流派"}},[a._v("#")]),a._v(" ROLAP流派")]),a._v(" "),v("p",[a._v("RDBMS、Hive、Impala、Spark Sql")]),a._v(" "),v("h3",{attrs:{id:"hive"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hive"}},[a._v("#")]),a._v(" Hive")]),a._v(" "),v("p",[a._v("1、Hive由 Facebook实现并开源\n2、是基于Hadoop的一个数据仓库工具\n3、可以将结构化的数据映射为一张数据库表\n4、并提供 HQL(Hive SQL)查询功能\n5、底层数据是存储在HDFS上\n6、Hive的本质是将SQL语句转换为MapReduce任务运行\n7、使不熟悉MapReduce的用户很方便地利用HQL理和计算HDFS上的结构化的数据，适用于离线的批量数据计算。")]),a._v(" "),v("p",[a._v("总结：使用Hive的目的直接使用MapReduce成本很高，为了直接使用sql查询大数据")]),a._v(" "),v("h3",{attrs:{id:"impala"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#impala"}},[a._v("#")]),a._v(" Impala")]),a._v(" "),v("p",[a._v("Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。\n已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。\n相比之下，Impala的最大特点也是最大卖点就是它的快速。")]),a._v(" "),v("h3",{attrs:{id:"spark"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#spark"}},[a._v("#")]),a._v(" Spark")]),a._v(" "),v("p",[a._v("又是Apache的一个产品。Apache Spark™ is a unified analytics engine for large-scale data processing.\nSpark是一个大数据数据分析系统，比MapReducer快40倍左右。\n能够通过Spark Sql读写HDFS HBASE Hive Impala。")]),a._v(" "),v("h2",{attrs:{id:"molap流派"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#molap流派"}},[a._v("#")]),a._v(" MOLAP流派")]),a._v(" "),v("p",[a._v("Druid，Pinot，Kylin、ElasticSearch。")]),a._v(" "),v("h3",{attrs:{id:"druid"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#druid"}},[a._v("#")]),a._v(" Druid")]),a._v(" "),v("p",[a._v("这里的Druid不是阿里的数据连接池，Druid是一个高效的数据查询系统，主要解决的是对于大量的基于时序的数据进行聚合查询。\n数据可以实时摄入，进入到Druid后立即可查，同时数据是几乎是不可变。\n通常是基于时序的事实事件，事实发生后进入Druid，外部系统就可以对该事实进行查询。")]),a._v(" "),v("p",[a._v("Druid由一家叫MetaMarkets的公司开发，目前像Yahoo、小米、阿里、百度等公司都在用它大量地做一些数据的实时分析，包括一些广告、搜索、用户的行为统计。它的特点包括：")]),a._v(" "),v("ol",[v("li",[a._v("为分析而设计\n为OLAP而生，它支持各种filter、aggregator和查询类型。")]),a._v(" "),v("li",[a._v("交互式查询\n低延迟数据，内部查询为毫秒级。")]),a._v(" "),v("li",[a._v("高可用性\n集群设计，去中性化规模的扩大和缩小不会造成数据丢失。")]),a._v(" "),v("li",[a._v("可伸缩\n现有的Druid部署每天处理数十亿事件和TB级数据。Druid被设计成PB级别。")])]),a._v(" "),v("p",[a._v("Druid相类似的实时数据分析工具，还有Linkedln的Pinot和eBay的Kylin，它们都是基于Java开发的。Druid相对比较轻量级，用的人也多，毕竟开发时间久一些，问题也少一些。")]),a._v(" "),v("h3",{attrs:{id:"elasticsearch"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch"}},[a._v("#")]),a._v(" ElasticSearch")]),a._v(" "),v("p",[a._v("全文搜索引擎，是目前全文搜索引擎的首选。它可以快速地储存、搜索和分析海量数据。维基百科、Stack Overflow、Github 都采用它。\n需要注意的是它不仅包括了全文搜索功能，还可以进行以下工作:")]),a._v(" "),v("ol",[v("li",[a._v("分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。")]),a._v(" "),v("li",[a._v("实时分析的分布式搜索引擎。")]),a._v(" "),v("li",[a._v("可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。")])]),a._v(" "),v("h2",{attrs:{id:"流处理平台"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#流处理平台"}},[a._v("#")]),a._v(" 流处理平台")]),a._v(" "),v("hr"),a._v(" "),v("p",[a._v("下面两个都是用来处理实时大数据的，或许东西一多我们又迷糊了，好像每个东西的功能都差不多。\n其实他们都各有侧重，用于不同的场景，后面通过解释几个常用的组合拳应该会有一个大致的概念。")]),a._v(" "),v("h3",{attrs:{id:"storm"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#storm"}},[a._v("#")]),a._v(" Storm")]),a._v(" "),v("p",[a._v("Storm和Hadoop框架都可用于分析大数据。\n与Hadoop相比，是一个分布式的实时计算系统，能够可信任的处理大量的"),v("code",[a._v("流式")]),a._v("数据。\nApache Storm是实时数据分析的领导者。")]),a._v(" "),v("p",[a._v("要点：")]),a._v(" "),v("h3",{attrs:{id:"kafka"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[a._v("#")]),a._v(" Kafka")]),a._v(" "),v("p",[a._v("Kafka是由Apache软件基金会开发的一个开源流处理平台，Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。\n这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。\n这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。\n对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。\nKafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。")]),a._v(" "),v("h1",{attrs:{id:"组合拳"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#组合拳"}},[a._v("#")]),a._v(" 组合拳")]),a._v(" "),v("hr"),a._v(" "),v("p",[a._v("回到文章开头的组合拳，理解了上述的概念后我们就具备了理解各种大数据平台架构的能力了。")]),a._v(" "),v("h3",{attrs:{id:"小米数据统计分析平台"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#小米数据统计分析平台"}},[a._v("#")]),a._v(" 小米数据统计分析平台")]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/ref/%E5%B0%8F%E7%B1%B3%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0-%E6%9E%B6%E6%9E%84.jpg",alt:"Alt text"}})]),a._v(" "),v("ol",[v("li",[a._v("手机、电视、电脑把事件通过网络传递到小米分析服务")]),a._v(" "),v("li",[a._v("分析服务会有两条路线:一条路是通过Scirbe采集Log到HDFS中，然后通过MapReduce计算存储到HBase或MySQL。\n另外一条路线利用Kafka的流处理能力，把各种实时事件经过Kafka一部分存储到ES、一部分存储到Druid，一部分经过Storm的计算集群把预计算算好，存到HBase中\n像分钟级这种平率比较高的就用第二条路线，天级的数据用第一条路线。\n每天最后会用Spark从HDFS中获取完整跑的Log到HBase去取代实时的数据，大概是这样一个过程。")]),a._v(" "),v("li",[a._v("实时分析时的取数就根据数据性质的不同从ES、HBase、MySQL、Druid分别获取。\n中间某些场景计算结果可以放到Redis中缓存起来，避免重复计算。")])]),a._v(" "),v("p",[a._v("这样在看文章开头的组合Hadoop+HBase+Flume+Kafk，其实就是日志采集Scirbe缓存了Flume。\n我们也理解了Hadoop+HBase+Flume+Kafk的真正意图是什么。")]),a._v(" "),v("h3",{attrs:{id:"酷狗大数据架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#酷狗大数据架构"}},[a._v("#")]),a._v(" 酷狗大数据架构")]),a._v(" "),v("p",[v("img",{attrs:{src:"/images/ref/%E9%85%B7%E7%8B%97%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84.jpg",alt:"Alt text"}})]),a._v(" "),v("p",[a._v("从上图中可以看出大数据处理过程可以分为数据源、数据接入、数据清洗、数据缓存、存储计算、数据服务、数据消费等环节。\n每个环节都应具有有高可用性、可扩展性等特性，每个环节都应当做一个复杂的系统来建设。")]),a._v(" "),v("p",[a._v("结合小米的架构，Kafka->Storm->HDFS的具体作用应该很清楚了。\n"),v("code",[a._v("Kafka")]),a._v("流式数据的采集，"),v("code",[a._v("Storm")]),a._v("流式数据的数据清洗，HDFS数据存储。")]),a._v(" "),v("p",[v("strong",[a._v("缓存重用:")]),a._v("\n上图中的架构多了一步，是Kafka->Storm->Kafka->Storm->HDFS。")]),a._v(" "),v("p",[a._v("Kafka->Storm->HDFS的架构，是推数据到HDFS的模式，需要维持HDFS Client的长连接，由于网络等各种原因导致Storm实时写入HDFS经常不稳定，隔三差五的出现数据异常，使后面的计算结果异常不断。")]),a._v(" "),v("p",[a._v("Kafka->Storm->Kafka->Storm->HDFS的架构是HDFS拉模式。\n为了避免大量数据流写入HDFS，导致HDFS客户端不稳定现象及数据实时性考虑，把经过数据实时清洗后的数据重新写入Kafka并保留一定周期，离线计算(批处理)，拉到HDFS(通过作业调度系统配置相应的作业计划)。")]),a._v(" "),v("h1",{attrs:{id:"结束语"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#结束语"}},[a._v("#")]),a._v(" 结束语")]),a._v(" "),v("p",[a._v("稍微看了下其它京东、阿里的大数据架构也差不多是这些套路，宏观上都可以理解。细节的东西还是在开发实践中具体学习。")])])}),[],!1,null,null,null);e.default=t.exports}}]);